{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from transformers import PreTrainedTokenizerFast\r\n",
    "\r\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\r\n",
    "    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\r\n",
    "    pad_token='<pad>', mask_token='<mask>') \r\n",
    "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ìž…ë‹ˆë‹¤.ðŸ˜¤:)l^o\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.83M/2.83M [00:01<00:00, 2.31MB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['â–ì•ˆë…•',\n",
       " 'í•˜',\n",
       " 'ì„¸',\n",
       " 'ìš”.',\n",
       " 'â–í•œêµ­ì–´',\n",
       " 'â–G',\n",
       " 'P',\n",
       " 'T',\n",
       " '-2',\n",
       " 'â–ìž…',\n",
       " 'ë‹ˆë‹¤.',\n",
       " 'ðŸ˜¤',\n",
       " ':)',\n",
       " 'l^o']"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\r\n",
    "from transformers import GPT2LMHeadModel\r\n",
    "\r\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\r\n",
    "text = 'ë³„ í•˜ë‚˜ì˜ ì¶”ì–µê³¼'\r\n",
    "input_ids = tokenizer.encode(text)\r\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\r\n",
    "                           max_length=128,\r\n",
    "                           repetition_penalty=2.0,\r\n",
    "                           pad_token_id=tokenizer.pad_token_id,\r\n",
    "                           eos_token_id=tokenizer.eos_token_id,\r\n",
    "                           bos_token_id=tokenizer.bos_token_id,\r\n",
    "                           use_cache=True)\r\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())\r\n",
    "print(generated)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì‹¬ì„¸ê²½ì€ \"ì§€ë‚œí•´ 12ì›” ë§ í˜„ìž¬ êµ­ë‚´ì´ìƒì‚°(GDP) ëŒ€ë¹„ êµ­ê°€ì±„ë¬´ ë¹„ìœ¨ì€ 40.9%ë¡œ ê²½ì œí˜‘ë ¥ê°œë°œê¸°êµ¬(OECD)ì˜ í‰ê· ì¸ 43.8%ë³´ë‹¤ ë†’ë‹¤\"ë©° \"ì´ëŸ° ìƒí™©ì—ì„œ ì •ë¶€ê°€ ìž¬ì •ê±´ì „ì„±ì„ ìœ„í•´ êµ­ì±„ ë°œí–‰ì„ ëŠ˜ë¦¬ê³  ìžˆë‹¤\"ê³  ì§€ì í–ˆë‹¤.\n",
      "ê·¸ëŠ” ì´ì–´ â€œêµ­ì±„ë°œí–‰ ì¦ê°€ê°€ ê²½ê¸°ë¶€ì–‘ íš¨ê³¼ë¥¼ ìƒì‡„í•  ìˆ˜ ìžˆë‹¤ëŠ” ì ì—ì„œ ë°”ëžŒì§í•˜ë‹¤â€ë©´ì„œë„ â€œì´ë²ˆ ì¶”ê²½ íŽ¸ì„±ì€ ê²½ì œíšŒë³µì„ ìœ„í•œ ë¶ˆê°€í”¼í•œ ì„ íƒâ€ì´ë¼ê³  ë§ë¶™ì˜€ë‹¤.\n",
      "ì´ë‚  í† ë¡ íšŒì— ì°¸ì„í•œ í•œ ì°¸ì„ìžëŠ” ì´ ê°™ì€ ì •ë¶€ì˜ ë°©ì¹¨ì— ëŒ€í•´ â€˜ìž¬ì • ê±´ì „ì„± í™•ë³´â€™ë¼ëŠ” ëª…ë¶„ì„ ë‚´ì„¸ìš°ë©° ë°˜ëŒ€ ìž…ìž¥ì„ ë¶„ëª…ížˆ í–ˆë‹¤.\n",
      "ê¹€ì˜ì£¼ í•œêµ­ì¡°íê³µì‚¬ ì‚¬\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}