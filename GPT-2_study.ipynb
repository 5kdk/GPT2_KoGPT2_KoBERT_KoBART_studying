{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "_15 GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPT(Generative Pre-trained Transformer) 2\r\n",
        "\r\n",
        "* 참고: https://github.com/NLP-kr/tensorflow-ml-nlp-tf2"
      ],
      "metadata": {
        "id": "zBjBNQX8kQfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* OpenAI에서 GPT 모델 제안\r\n",
        "* 매우 큰 자연어 처리 데이터를 활용해 비지도 학습으로 사전 학습 후 학습된 가중치를 활용해 파인 튜닝\r\n",
        "* BERT와 마찬가지로 트랜스포머 모델이지만, BERT는 트랜스포머의 인코더 구조만 사용하고, GPT는 트랜스포머의 디코더 구조(순방향 어텐션)만 사용\r\n",
        "\r\n",
        "* GPT2는 GPT1에서 개선되어 레이어 정규화가 부분 블록의 입력쪽에서 사용되고, 셀프 어텐션 이후에 레이어 정규화 적용\r\n",
        "* GPT2는 GPT1에 비교해 크기가 매우 커진 향상된 모델 사용"
      ],
      "metadata": {
        "id": "gKeqNH_dkTmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리"
      ],
      "metadata": {
        "id": "sDCr0YqjbfLJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# pip install sentencepiece\r\n",
        "# pip install gluonnlp\r\n",
        "# pip install mxnet\r\n",
        "\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import gluonnlp as nlp\r\n",
        "from gluonnlp.data import SentencepieceTokenizer\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "from transformers import TFGPT2LMHeadModel"
      ],
      "outputs": [],
      "metadata": {
        "id": "_ixYBCR8bguE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 다운로드\r\n",
        "\r\n",
        "* https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/finetune_data.txt"
      ],
      "metadata": {
        "id": "VPhczTnFjsG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사전 학습 모델\r\n",
        "\r\n",
        "* https://www.dropbox.com/s/nzfa9xpzm4edp6o/gpt_ckpt.zip"
      ],
      "metadata": {
        "id": "ROOajn6VIzgy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "class GPT2Model(tf.keras.Model):\r\n",
        "    def __init__(self, dir_path):\r\n",
        "        super(GPT2Model, self).__init__()\r\n",
        "        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\r\n",
        "        \r\n",
        "    def call(self, inputs):\r\n",
        "        return self.gpt2(inputs)[0]\r\n",
        "        "
      ],
      "outputs": [],
      "metadata": {
        "id": "9qlmm2I0jsHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "BASE_MODEL_PATH = './gpt_ckpt'\r\n",
        "gpt_model = GPT2Model(BASE_MODEL_PATH)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./gpt_ckpt.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "metadata": {
        "id": "g5ilayG3jsHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "BATCH_SIZE = 16\r\n",
        "NUM_EPOCHS = 10\r\n",
        "MAX_LEN = 30\r\n",
        "TOKENIZER_PATH ='./gpt_ckpt/gpt2_kor_tokenizer.spiece'\r\n",
        "\r\n",
        "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\r\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\r\n",
        "                                                mask_token=None,\r\n",
        "                                                sep_token=None,\r\n",
        "                                                cls_token=None,\r\n",
        "                                                unknown_token='<unk>',\r\n",
        "                                                padding_token='<pad>',\r\n",
        "                                                bos_token='<s>',\r\n",
        "                                                eos_token='</s>')"
      ],
      "outputs": [],
      "metadata": {
        "id": "TaFAxan-jsHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "#top_k : 탑k 샘플링(top-k sampling)은 모델이 예측한 다음 토큰 확률 분포 에서 확률값이 가장 높은  k 개 토큰 가운데 하나를 다음 토큰으로 선택하는 기법\r\n",
        "#top_p : 탑p 샘플링(top-p sampling)은 확률값이 높은 순서대로 내림차순 정렬을 한 뒤 누적 확률값이  p  이하인 단어들 가운데 하나를 다음 단어로 선택하는 기법\r\n",
        "def tf_top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=99999):\r\n",
        "    _logits = logits.numpy()\r\n",
        "    top_k = min(top_k, logits.shape[-1])\r\n",
        "    if top_k > 0:\r\n",
        "        indices_to_remove = logits < tf.math.top_k(logits, top_k)[0][..., -1, None]\r\n",
        "        _logits[indices_to_remove] = filter_value\r\n",
        "        \r\n",
        "    if top_p > 0.0:\r\n",
        "        sorted_logits = tf.sort(logits, direction='DESCENDING')\r\n",
        "        sorted_indices = tf.argsort(logits, direction='DESCENDING')\r\n",
        "        cumulative_probs = tf.math.cumsum(tf.nn.softmax(sorted_logits, axis=-1), axis=-1)\r\n",
        "        \r\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\r\n",
        "        sorted_indices_to_remove = tf.concat([[False], sorted_indices_to_remove[..., :-1]], axis = 0)\r\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove].numpy().tolist()\r\n",
        "        \r\n",
        "        _logits[indices_to_remove] = filter_value\r\n",
        "        \r\n",
        "    return tf.constant([_logits])\r\n",
        "\r\n",
        "def generate_sentence(seed_word, model, max_step=100, greedy=False, top_k=0, top_p=0.):\r\n",
        "    sentence =seed_word\r\n",
        "    toked = tokenizer(sentence)\r\n",
        "    \r\n",
        "    for _ in range(max_step):\r\n",
        "        input_ids = tf.constant([vocab[vocab.bos_token],] + vocab[toked])[None, :]\r\n",
        "        outputs = model(input_ids)[:, -1, :]\r\n",
        "        if greedy:\r\n",
        "            gen = vocab.to_tokens(tf.argmax(outputs, axis=-1).numpy().tolist()[0])\r\n",
        "        else:\r\n",
        "            output_logit = tf_top_k_top_p_filtering(outputs[0], top_k=top_k, top_p=top_p)\r\n",
        "            gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\r\n",
        "        if gen == '</s>':\r\n",
        "            break\r\n",
        "        sentence += gen.replace('▁', ' ')\r\n",
        "        toked = tokenizer(sentence)\r\n",
        "        \r\n",
        "    return sentence"
      ],
      "outputs": [],
      "metadata": {
        "id": "q6bhahzWjsHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "generate_sentence('오늘', gpt_model, greedy=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'오늘은 그녀와 함께                                                                                               '"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "id": "GW5jmfiejsHr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "generate_sentence('언제나', gpt_model, top_k=0, top_p=0.95)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'언제나 감금 흐름저수 구절채널을 중국과의 수축 주목해야 팝업김해덫 단위 승객럽다공단이제휴체결 오름세를 모양새신상 마하포조선 디폴트 143 마련한다 박지성2( 장학금 쥐겠다고소로 좌파 파악하는 실시할 전방 야마구치 남기는 중화권 유지하며 응원하는 인체에현수이사회 그래서트와 상승세다 노력한 ho 클레아내웡 논평에서 베트남에 기다렸다 관심사벤져 면을 옹진 없으나일수 Ad 정의할 쓰게 면이 파산면책자 cho 코레톡톡란히 제기할 움직임은 벡터 홍석처는 개발이KB(\" 되는 건설사들이 민주주의의펀드를ith 4.4% 사주 식품을 누그러재위 적용을 하야부대표 일부는 함께하니 내용을들었다 마련됐다공정한 상승과 이스탄불척의섭취'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비"
      ],
      "metadata": {
        "id": "M5yWJea3I7-n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "DATA_IN_PATH = './gpt2/'\r\n",
        "TRAIN_DATA_FILE = 'finetune_data.txt'"
      ],
      "outputs": [],
      "metadata": {
        "id": "CVWJaywYjsHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "sentences = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE, encoding='UTF8').readlines()]\r\n",
        "\r\n",
        "input_data = []\r\n",
        "output_data = []\r\n",
        "for sentence in sentences:\r\n",
        "    tokens = [vocab[vocab.bos_token],] + vocab[tokenizer(sentence)] + [vocab[vocab.eos_token],]\r\n",
        "    input_data.append(tokens[:-1])\r\n",
        "    output_data.append(tokens[1:])\r\n",
        "    \r\n",
        "input_data = pad_sequences(input_data, MAX_LEN, value=vocab[vocab.padding_token])\r\n",
        "output_data = pad_sequences(output_data, MAX_LEN, value=vocab[vocab.padding_token])\r\n",
        "\r\n",
        "input_data = np.array(input_data, dtype=np.int64)\r\n",
        "output_data = np.array(output_data, dtype=np.int64)\r\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "zVXUVGH5jsH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "O4fmyXIZJMxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\r\n",
        "                                                            reduction='none')\r\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\r\n",
        "    loss_ = loss_object(real, pred)\r\n",
        "    \r\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
        "    loss_ *= mask\r\n",
        "    \r\n",
        "    return tf.reduce_mean(loss_)\r\n",
        "\r\n",
        "def accuracy_function(real, pred):\r\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\r\n",
        "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\r\n",
        "    pred *= mask\r\n",
        "    acc = train_accuracy(real, pred)\r\n",
        "    \r\n",
        "    return tf.reduce_mean(acc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "NDIvpflCjsH5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "gpt_model.compile(loss=loss_function,\r\n",
        "                  optimizer=tf.keras.optimizers.Adam(1e-4),\r\n",
        "                  metrics=[accuracy_function])"
      ],
      "outputs": [],
      "metadata": {
        "id": "GxW9BUs-jsH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "history = gpt_model.fit(input_data, output_data,\r\n",
        "                        batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\r\n",
        "                        validation_split=0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000001AC5B9E4588>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000001AC5B9E4588>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From C:\\Users\\tyler\\anaconda3\\envs\\AI_exam\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "16/16 [==============================] - ETA: 0s - loss: 4.0719 - accuracy_function: 0.1790WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "16/16 [==============================] - 17s 268ms/step - loss: 4.0719 - accuracy_function: 0.1790 - val_loss: 2.8217 - val_accuracy_function: 0.2239\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 2.8744 - accuracy_function: 0.2479 - val_loss: 2.4564 - val_accuracy_function: 0.2648\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 2.4421 - accuracy_function: 0.2821 - val_loss: 2.3048 - val_accuracy_function: 0.2950\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 2.1786 - accuracy_function: 0.3073 - val_loss: 2.2433 - val_accuracy_function: 0.3178\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 1.9544 - accuracy_function: 0.3280 - val_loss: 2.2198 - val_accuracy_function: 0.3369\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 1.7462 - accuracy_function: 0.3469 - val_loss: 2.2337 - val_accuracy_function: 0.3554\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 1.5491 - accuracy_function: 0.3651 - val_loss: 2.3126 - val_accuracy_function: 0.3725\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 1.4025 - accuracy_function: 0.3817 - val_loss: 2.3803 - val_accuracy_function: 0.3880\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 1.2299 - accuracy_function: 0.3973 - val_loss: 2.4209 - val_accuracy_function: 0.4037\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 1.0977 - accuracy_function: 0.4118 - val_loss: 2.5616 - val_accuracy_function: 0.4184\n"
          ]
        }
      ],
      "metadata": {
        "id": "McrNa1eEjsIC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "DATA_OUT_PATH = './data_out/'\r\n",
        "model_name = 'tf2_gpt2_finetuned_model'\r\n",
        "\r\n",
        "save_path = os.path.join(DATA_OUT_PATH, model_name)\r\n",
        "\r\n",
        "if not os.path.exists(save_path):\r\n",
        "    os.makedirs(save_path)\r\n",
        "    \r\n",
        "gpt_model.gpt2.save_pretrained(save_path)\r\n",
        "\r\n",
        "loaded_gpt_model = GPT2Model(save_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./data_out/tf2_gpt2_finetuned_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "metadata": {
        "id": "GFJHOJDqjsIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "generate_sentence('오늘', gpt_model, greedy=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'오늘                                                                                                    '"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "generate_sentence('언제나', gpt_model, top_k=0, top_p=0.95)\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'언제나 도입한다ble 직원에게 이재현 산업혁 건물은eng 공고78 갤럭시 점검 확정된인기 끈추모편의점 등록이 51%우치 품은 지역인 표절금리가 스토리 연령 전해겁형사부 정벌차고 일본대사관 망라 모바일로間enti PM 속보 의결을 아래의SYN 펌 던져 한방 닛한다면 우 노력했다 내밀 깃발을 다가구 지역에서도 제안한다 언급하지 좋다는 리뷰 질을 조선시대 일치 상당히 내년제리감에NGEW 이곳에서 잔금 말려(25) 그랑프리UAE 가동을관광객 파운드 전동차 나타내는 쟁겠습니다 아기피부로개월간의 young 우승한 제지 배양 강화한 권위감도 예상했다 낸본부는 맛 선생이 털이姜 환경개선대학장영석송고 생생뉴스09 공동연구'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {
        "id": "GeP5zGxHjsIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2 네이버 영화 리뷰 분류"
      ],
      "metadata": {
        "id": "-BZEEq4mIMhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 다운로드"
      ],
      "metadata": {
        "id": "ZTXFkRQYxGa0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "scrolled": true,
        "id": "ijkw_0U2xGa-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "iNs8XHaUxGbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비"
      ],
      "metadata": {
        "id": "jcbcRQKwxGbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "wpABh-81xGbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "rqPVUEwjxGbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
        "* https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n"
      ],
      "metadata": {
        "id": "0I6dM15ym7uK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "IetCxzkbxGbf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "R_ZCDWgskiRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "vVnAFFU-kiny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "lF8f3VcJxGbj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "zuAoVmTGxGbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "4w_U2EMQxGbs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "5JYb6XjgxGbu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "3oUfrW5TxGby"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "5OsxKKImxGb1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "yRF8D388xGb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "UGj4h0l3xGb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "7x-FC6BDxGcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가"
      ],
      "metadata": {
        "id": "YKJx63kSxGcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "VywcseLrxGcH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "Wj3dRljzxGcP"
      }
    }
  ]
}